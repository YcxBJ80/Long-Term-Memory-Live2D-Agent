"""
memU ç¬”è®°å®¢æˆ·ç«¯
ç”¨äºå°†ç¬”è®°ç›´æ¥å­˜å‚¨åˆ° memU è®°å¿†åº“ä¸­
"""

import httpx
from typing import Optional, List, Dict, Any
from datetime import datetime
import json


class MemuNoteClient:
    """memU ç¬”è®°å®¢æˆ·ç«¯ï¼Œç”¨äºå­˜å‚¨å’Œç®¡ç†ç¬”è®°"""

    def __init__(
        self,
        base_url: str = "http://127.0.0.1:8000",
        user_id: str = "note_user",
        user_name: str = "ç¬”è®°ç”¨æˆ·",
        agent_id: str = "note_agent",
        agent_name: str = "ç¬”è®°åŠ©æ‰‹",
        timeout: float = 30.0,
    ):
        """
        åˆå§‹åŒ– memU ç¬”è®°å®¢æˆ·ç«¯

        Args:
            base_url: memU API çš„åŸºç¡€ URL
            user_id: ç”¨æˆ·æ ‡è¯†
            user_name: ç”¨æˆ·åç§°
            agent_id: æ™ºèƒ½ä½“æ ‡è¯†
            agent_name: æ™ºèƒ½ä½“åç§°
            timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        """
        self.base_url = base_url.rstrip("/")
        self.user_id = user_id
        self.user_name = user_name
        self.agent_id = agent_id
        self.agent_name = agent_name
        self.timeout = timeout

    def _generate_tags_with_llm(self, title: str, content: str) -> List[str]:
        """
        ä½¿ç”¨ LLM è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾

        Args:
            title: ç¬”è®°æ ‡é¢˜
            content: ç¬”è®°å†…å®¹

        Returns:
            ç”Ÿæˆçš„æ ‡ç­¾åˆ—è¡¨
        """
        try:
            # æ„å»ºæç¤ºè¯
            prompt = f"""è¯·ä¸ºä»¥ä¸‹ç¬”è®°ç”Ÿæˆ3-5ä¸ªç›¸å…³çš„æ ‡ç­¾å…³é”®è¯ã€‚

ç¬”è®°æ ‡é¢˜ï¼š{title}
ç¬”è®°å†…å®¹ï¼š{content}

è¦æ±‚ï¼š
1. æ ‡ç­¾åº”è¯¥ç®€æ´æ˜äº†ï¼Œ2-4ä¸ªå­—
2. æ ‡ç­¾åº”è¯¥æ¶µç›–ä¸»é¢˜ã€é¢†åŸŸã€ç±»å‹ç­‰ç»´åº¦
3. åªè¿”å›æ ‡ç­¾ï¼Œç”¨é€—å·åˆ†éš”ï¼Œä¸è¦å…¶ä»–å†…å®¹

æ ‡ç­¾ï¼š"""

            # è°ƒç”¨ LLMï¼ˆé€šè¿‡ memU çš„ APIï¼‰
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªç®€å•çš„å¯å‘å¼æ–¹æ³•ç”Ÿæˆæ ‡ç­¾
            # å®é™…ä¸Š memU ä¼šåœ¨åå°ç”¨ LLM å¤„ç†ï¼Œæ‰€ä»¥æˆ‘ä»¬è®©å®ƒè‡ªåŠ¨æå–
            
            # ä»æ ‡é¢˜å’Œå†…å®¹ä¸­æå–å…³é”®è¯ä½œä¸ºä¸´æ—¶æ–¹æ¡ˆ
            import re
            
            # åˆå¹¶æ ‡é¢˜å’Œå†…å®¹
            text = f"{title} {content}"
            
            # ç®€å•çš„å…³é”®è¯æå–ï¼ˆå®é™…ä¸Š memU ä¼šåšæ›´å¥½çš„å¤„ç†ï¼‰
            keywords = []
            
            # å¸¸è§æŠ€æœ¯å…³é”®è¯
            tech_keywords = [
                'Python', 'Java', 'JavaScript', 'AI', 'äººå·¥æ™ºèƒ½', 'æœºå™¨å­¦ä¹ ', 
                'æ·±åº¦å­¦ä¹ ', 'ç¥ç»ç½‘ç»œ', 'ç®—æ³•', 'æ•°æ®ç»“æ„', 'ç¼–ç¨‹', 'å¼€å‘',
                'å‰ç«¯', 'åç«¯', 'æ•°æ®åº“', 'Web', 'ç§»åŠ¨å¼€å‘', 'äº‘è®¡ç®—',
                'å­¦ä¹ ', 'å·¥ä½œ', 'é¡¹ç›®', 'æŠ€æœ¯', 'ç¬”è®°', 'æ€»ç»“', 'æ•™ç¨‹',
                'æ¡†æ¶', 'åº“', 'å·¥å…·', 'æ–¹æ³•', 'å®è·µ', 'ç»éªŒ'
            ]
            
            for keyword in tech_keywords:
                if keyword in text:
                    keywords.append(keyword)
                    if len(keywords) >= 5:
                        break
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…³é”®è¯ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾
            if not keywords:
                keywords = ['ç¬”è®°', 'å­¦ä¹ ']
            
            return keywords[:5]  # æœ€å¤šè¿”å›5ä¸ªæ ‡ç­¾
            
        except Exception as e:
            print(f"âš ï¸  è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾: {e}")
            return ['ç¬”è®°', 'å­¦ä¹ ']

    def save_note(
        self,
        title: str,
        content: str,
        tags: Optional[List[str]] = None,
        category: str = "note",
        auto_tags: bool = True,
    ) -> Dict[str, Any]:
        """
        ä¿å­˜ç¬”è®°åˆ° memU

        Args:
            title: ç¬”è®°æ ‡é¢˜
            content: ç¬”è®°å†…å®¹
            tags: æ ‡ç­¾åˆ—è¡¨ï¼ˆå¦‚æœä¸º None ä¸” auto_tags=Trueï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆï¼‰
            category: ç¬”è®°åˆ†ç±»
            auto_tags: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾

        Returns:
            API å“åº”ç»“æœ
        """
        # å¦‚æœæ²¡æœ‰æä¾›æ ‡ç­¾ä¸”å¯ç”¨è‡ªåŠ¨æ ‡ç­¾ï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆ
        if not tags and auto_tags:
            print("ğŸ¤– æ­£åœ¨ä½¿ç”¨ AI è‡ªåŠ¨ç”Ÿæˆæ ‡ç­¾...")
            tags = self._generate_tags_with_llm(title, content)
            print(f"âœ¨ è‡ªåŠ¨ç”Ÿæˆçš„æ ‡ç­¾: {', '.join(tags)}")
        
        # æ„å»ºå¯¹è¯æ ¼å¼çš„ç¬”è®°
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # æ„å»ºç¬”è®°æ¶ˆæ¯
        note_message = f"[ç¬”è®°] {title}\n\n{content}"
        if tags:
            note_message += f"\n\næ ‡ç­¾: {', '.join(tags)}"
        note_message += f"\n\nè®°å½•æ—¶é—´: {timestamp}"

        # æ„å»ºå¯¹è¯æ•°æ®
        conversation_data = {
            "user_id": self.user_id,
            "user_name": self.user_name,
            "agent_id": self.agent_id,
            "agent_name": self.agent_name,
            "conversation": [
                {
                    "role": "user",
                    "content": note_message,
                }
            ],
            "metadata": {
                "type": "note",
                "title": title,
                "category": category,
                "tags": tags or [],
                "timestamp": timestamp,
            },
        }

        # å‘é€åˆ° memU
        try:
            with httpx.Client(base_url=self.base_url, timeout=self.timeout) as client:
                response = client.post(
                    "/api/v1/memory/memorize",
                    json=conversation_data,
                )
                response.raise_for_status()
                result = response.json()
                print(f"âœ… ç¬”è®°å·²ä¿å­˜åˆ° memU: {title}")
                return result
        except httpx.HTTPError as e:
            print(f"âŒ ä¿å­˜ç¬”è®°å¤±è´¥: {e}")
            raise

    def search_notes(
        self,
        query: str,
        top_k: int = 10,
        min_similarity: float = 0.3,
    ) -> List[Dict[str, Any]]:
        """
        æœç´¢ç¬”è®°

        Args:
            query: æœç´¢æŸ¥è¯¢
            top_k: è¿”å›ç»“æœæ•°é‡
            min_similarity: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        search_data = {
            "user_id": self.user_id,
            "agent_id": self.agent_id,
            "query": query,
            "top_k": top_k,
            "min_similarity": min_similarity,
        }

        try:
            with httpx.Client(base_url=self.base_url, timeout=self.timeout) as client:
                response = client.post(
                    "/api/v1/memory/retrieve/related-memory-items",
                    json=search_data,
                )
                response.raise_for_status()
                result = response.json()
                
                memories = result.get("related_memories", [])
                notes = []
                
                for item in memories:
                    memory = item.get("memory", {})
                    similarity = item.get("similarity_score", 0.0)
                    
                    notes.append({
                        "memory_id": memory.get("memory_id"),
                        "category": memory.get("category"),
                        "content": memory.get("content"),
                        "similarity_score": similarity,
                        "metadata": memory.get("metadata", {}),
                    })
                
                print(f"ğŸ” æ‰¾åˆ° {len(notes)} æ¡ç›¸å…³ç¬”è®°")
                return notes
                
        except httpx.HTTPError as e:
            print(f"âŒ æœç´¢ç¬”è®°å¤±è´¥: {e}")
            raise

    def list_all_memories(self) -> List[Dict[str, Any]]:
        """
        åˆ—å‡ºæ‰€æœ‰è®°å¿†ï¼ˆç¬”è®°ï¼‰
        ç›´æ¥è¯»å– memU å­˜å‚¨çš„ markdown æ–‡ä»¶

        Returns:
            æ‰€æœ‰è®°å¿†åˆ—è¡¨
        """
        import re
        from pathlib import Path
        
        # memU å­˜å‚¨è·¯å¾„
        memory_base = Path("../memU/memory_data") / self.agent_id / self.user_id
        
        # å¦‚æœè·¯å¾„ä¸å­˜åœ¨ï¼Œå°è¯•ç»å¯¹è·¯å¾„
        if not memory_base.exists():
            memory_base = Path("/Users/yangchengxuan/Desktop/PROJECTS/Live2Document_4/memU/memory_data") / self.agent_id / self.user_id
        
        if not memory_base.exists():
            print("ğŸ“­ è¿˜æ²¡æœ‰ä»»ä½•ç¬”è®°")
            print(f"ğŸ’¡ æç¤ºï¼šç¬”è®°å­˜å‚¨è·¯å¾„ {memory_base} ä¸å­˜åœ¨")
            return []
        
        all_memories = []
        memory_count = 0
        
        # è¯»å–æ‰€æœ‰ .md æ–‡ä»¶
        for md_file in memory_base.glob("*.md"):
            category = md_file.stem
            
            try:
                with open(md_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # è§£ææ¯ä¸€è¡Œè®°å¿†ï¼ˆæ ¼å¼ï¼š[id][mentioned at date] content []ï¼‰
                lines = content.strip().split('\n')
                for line in lines:
                    if not line.strip():
                        continue
                    
                    # æå–è®°å¿† ID å’Œå†…å®¹
                    match = re.match(r'\[([^\]]+)\]\[mentioned at ([^\]]+)\]\s*(.+?)\s*\[\]', line)
                    if match:
                        memory_id = match.group(1)
                        date = match.group(2)
                        text = match.group(3)
                        
                        # æå–æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ï¼‰
                        tags = []
                        # å°è¯•å¤šç§æ ‡ç­¾æ ¼å¼
                        tag_patterns = [
                            r'æ ‡ç­¾[ï¼š:]\s*([^ã€‚\n]+)',
                            r'æ ‡è®°ä¸»é¢˜æ ‡ç­¾ä¸º\s*([^ã€‚\n]+)',
                            r'æ‰“ä¸Šæ ‡ç­¾\s*([^ã€‚\n]+)',
                            r'ä¸»é¢˜æ ‡ç­¾[ï¼š:]\s*([^ã€‚\n]+)',
                        ]
                        
                        for pattern in tag_patterns:
                            tag_match = re.search(pattern, text)
                            if tag_match:
                                tags_str = tag_match.group(1)
                                # åˆ†å‰²æ ‡ç­¾ï¼ˆæ”¯æŒå¤šç§åˆ†éš”ç¬¦ï¼‰
                                tags = [t.strip() for t in re.split(r'[,ï¼Œã€å’Œä¸åŠ]', tags_str) if t.strip()]
                                break
                        
                        all_memories.append({
                            'memory_id': memory_id,
                            'category': category,
                            'date': date,
                            'content': text,
                            'tags': tags,
                        })
                        memory_count += 1
            
            except Exception as e:
                print(f"âš ï¸  è¯»å–æ–‡ä»¶ {md_file} å¤±è´¥: {e}")
                continue
        
        if memory_count == 0:
            print("ğŸ“­ è¿˜æ²¡æœ‰ä»»ä½•ç¬”è®°")
        else:
            print(f"ğŸ“š å…±æœ‰ {memory_count} æ¡è®°å¿†")
        
        return all_memories


def main():
    """å‘½ä»¤è¡Œæµ‹è¯•"""
    client = MemuNoteClient()
    
    # æµ‹è¯•ä¿å­˜ç¬”è®°
    print("\nğŸ“ æµ‹è¯•ä¿å­˜ç¬”è®°...")
    client.save_note(
        title="Python å­¦ä¹ ç¬”è®°",
        content="ä»Šå¤©å­¦ä¹ äº† Python çš„è£…é¥°å™¨ã€‚è£…é¥°å™¨æ˜¯ä¸€ç§è®¾è®¡æ¨¡å¼ï¼Œå¯ä»¥åœ¨ä¸ä¿®æ”¹åŸå‡½æ•°çš„æƒ…å†µä¸‹å¢åŠ é¢å¤–åŠŸèƒ½ã€‚",
        tags=["Python", "ç¼–ç¨‹", "å­¦ä¹ "],
        category="æŠ€æœ¯ç¬”è®°",
    )
    
    # æµ‹è¯•æœç´¢ç¬”è®°
    print("\nğŸ” æµ‹è¯•æœç´¢ç¬”è®°...")
    results = client.search_notes("Python è£…é¥°å™¨")
    
    for i, note in enumerate(results, 1):
        print(f"\n--- ç¬”è®° {i} ---")
        print(f"ç›¸ä¼¼åº¦: {note['similarity_score']:.2f}")
        print(f"åˆ†ç±»: {note['category']}")
        print(f"å†…å®¹: {note['content'][:100]}...")


if __name__ == "__main__":
    main()
